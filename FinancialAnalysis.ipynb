{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinancialAnalysis.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOjVv60DZUiOQ0FtgursV3y"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Twitter Dataset with API\n",
        "\n",
        "Twitter offers the past seven days of data on their free API tier, so we will go back in 60-minute windows and extract ~100 tweets from within each of these windows. Requires bearer tokens as from registration process with Twitter for developer access."
      ],
      "metadata": {
        "id": "ZtfboBIx3sg5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nqfUR0P12Ml6"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('bearer_token.txt') as fp:\n",
        "    BEARER_TOKEN = fp.read()"
      ],
      "metadata": {
        "id": "N9snpVG037y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = 'https://api.twitter.com/2/tweets/search/recent'\n",
        "headers = {'authorization': f'Bearer {BEARER_TOKEN}'}\n",
        "params = {\n",
        "    'query': '(amazon OR aws OR jeff bezos) (lang:en)',\n",
        "    'max_results': '100',\n",
        "    'tweet.fields': 'created_at, lang'}"
      ],
      "metadata": {
        "id": "RQGqeGog38nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtformat = '%Y-%m-%dT%H:%M:%SZ'"
      ],
      "metadata": {
        "id": "3wdzCcAQ3_44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def time_periods(now, mins):\n",
        "    now = datetime.strptime(now, dtformat)\n",
        "    intervals_time = now - timedelta(minutes=mins) # time series at mins intervals\n",
        "    return intervals_time.strftime(dtformat)"
      ],
      "metadata": {
        "id": "ldE7kOf34HxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "now = datetime.now()  # get the current datetime, this is our starting point\n",
        "last_week = now - timedelta(days=7)  # datetime one week ago = the finish line\n",
        "now = now.strftime(dtformat)  # convert now datetime to format for API"
      ],
      "metadata": {
        "id": "4yd5CqhO5Qo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()"
      ],
      "metadata": {
        "id": "B9hX5I3O5hiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def twitter_data(tweet):\n",
        "    data = {\n",
        "        'id': tweet['id_str'],\n",
        "        'created_at': tweet['created_at'],\n",
        "        'text': tweet['full_text']\n",
        "    }\n",
        "    return data"
      ],
      "metadata": {
        "id": "kp9T0lb154l9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    if datetime.strptime(now, dtformat) < last_week:\n",
        "        break # loop based on earliest time\n",
        "      \n",
        "    pre60 = time_periods(now, 60)\n",
        "    params['start_time'] = pre60\n",
        "    params['end_time'] = now\n",
        "    response = requests.get(endpoint,\n",
        "                            params=params,\n",
        "                            headers=headers)\n",
        "    now = pre60\n",
        "\n",
        "    for tweet in response.json()['data']:\n",
        "        row = twitter_data(tweet)\n",
        "        df = df.append(row, ignore_index=True)"
      ],
      "metadata": {
        "id": "5BMaXIIZ5jEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gathering Financial News\n",
        "\n",
        "Historical analyst headlines and financial news headlines over several years on a sample of listed companies. Sentiment analysis using flair; classification into positive / negative with probability."
      ],
      "metadata": {
        "id": "MGjRAMPl-XbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFi8tvBp-ah_",
        "outputId": "1e929c3f-14fb-4bb9-8ace-d78e7b146bc8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_folder='/content/drive/My Drive/DataAnalysis'"
      ],
      "metadata": {
        "id": "eM7qcZRk-ukO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(root_folder+'/analyst_ratings_processed.csv')\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJU72hoM-wG0",
        "outputId": "2739efcd-6b22-4a9b-8b6a-ca736e58ddd8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1400469 entries, 0 to 1400468\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count    Dtype  \n",
            "---  ------      --------------    -----  \n",
            " 0   Unnamed: 0  1399180 non-null  float64\n",
            " 1   title       1400469 non-null  object \n",
            " 2   date        1399180 non-null  object \n",
            " 3   stock       1397891 non-null  object \n",
            "dtypes: float64(1), object(3)\n",
            "memory usage: 42.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.dropna(axis=0)"
      ],
      "metadata": {
        "id": "MG5oPhfSEZdx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['date'] = data['date'].str.split(' ').str[0]\n",
        "data['date'] = pd.Series(pd.to_datetime(data['date'], format='%Y-%m-%d')) # 2020-06-05 10:30:00-04:00"
      ],
      "metadata": {
        "id": "Oo5PU8G--0g7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop('Unnamed: 0', axis=1)"
      ],
      "metadata": {
        "id": "9whjL_wOE1Rf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flair / DistilBERT\n",
        "\n",
        "This model splits the text into character-level tokens and uses the DistilBERT model to make predictions.The advantage of working at the character-level (as opposed to word-level) is that words that the network has never seen before can still be assigned a sentiment. DistilBERT is a distilled version of the powerful BERT transformer model"
      ],
      "metadata": {
        "id": "X6WNF9WKIhmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import flair\n",
        "sentiment_model = flair.models.TextClassifier.load('en-sentiment')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5upNGYmGy1g",
        "outputId": "52824632-1986-458c-a920-29faf050e359"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-20 22:01:09,439 loading file /root/.flair/models/sentiment-en-mix-distillbert_4.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.sample(n = 1000, replace = False)\n",
        "data['text_clean'] = data['title'].apply(lambda x : text_cleaner(x))"
      ],
      "metadata": {
        "id": "b0annuv0HURZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['text_obj'] = data['text_clean'].apply(lambda x : flair.data.Sentence(x))\n",
        "data['text_obj'].apply(lambda x : sentiment_model.predict(x))\n",
        "data['score'] = data['text_obj'].apply(lambda x : x.labels[0].score)\n",
        "data['value'] = data['text_obj'].apply(lambda x : x.labels[0].value)"
      ],
      "metadata": {
        "id": "anCXBuwRHpTk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "id": "2TJ3n2RiLPs6",
        "outputId": "697a88ea-afae-4f20-f47c-fe28326727ed"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2bb1f8b3-350c-4f68-bba5-7503fcfe6298\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>date</th>\n",
              "      <th>stock</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_obj</th>\n",
              "      <th>score</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>336161</th>\n",
              "      <td>Diebold's Planned Acquisition Of Wincor Nixdor...</td>\n",
              "      <td>2016-05-31</td>\n",
              "      <td>DBD</td>\n",
              "      <td>diebold s planned acquisition of wincor nixdor...</td>\n",
              "      <td>(Token: 1 diebold, Token: 2 s, Token: 3 planne...</td>\n",
              "      <td>0.556393</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570059</th>\n",
              "      <td>Atlantic Equities Downgrades Garmin to Neutral...</td>\n",
              "      <td>2015-02-20</td>\n",
              "      <td>GRMN</td>\n",
              "      <td>atlantic equities downgrades garmin to neutral...</td>\n",
              "      <td>(Token: 1 atlantic, Token: 2 equities, Token: ...</td>\n",
              "      <td>0.998690</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1264993</th>\n",
              "      <td>TherapeuticsMD Reports Resubmission Of NDA For...</td>\n",
              "      <td>2017-11-29</td>\n",
              "      <td>TXMD</td>\n",
              "      <td>therapeuticsmd reports resubmission of nda for...</td>\n",
              "      <td>(Token: 1 therapeuticsmd, Token: 2 reports, To...</td>\n",
              "      <td>0.984767</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>478804</th>\n",
              "      <td>FAA To Streamline Fire Regulations For Cargo C...</td>\n",
              "      <td>2019-07-03</td>\n",
              "      <td>FDX</td>\n",
              "      <td>faa to streamline fire regulations for cargo c...</td>\n",
              "      <td>(Token: 1 faa, Token: 2 to, Token: 3 streamlin...</td>\n",
              "      <td>0.790327</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1232600</th>\n",
              "      <td>Earnings Scheduled For February 25, 2014</td>\n",
              "      <td>2014-02-25</td>\n",
              "      <td>TOL</td>\n",
              "      <td>earnings scheduled for february</td>\n",
              "      <td>(Token: 1 earnings, Token: 2 scheduled, Token:...</td>\n",
              "      <td>0.872605</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1036042</th>\n",
              "      <td>American Petro-Hunter's Sacramento Gas Project...</td>\n",
              "      <td>2009-08-10</td>\n",
              "      <td>Q</td>\n",
              "      <td>american petro hunter s sacramento gas project...</td>\n",
              "      <td>(Token: 1 american, Token: 2 petro, Token: 3 h...</td>\n",
              "      <td>0.612436</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1119241</th>\n",
              "      <td>Morning Market Losers</td>\n",
              "      <td>2013-06-10</td>\n",
              "      <td>SHI</td>\n",
              "      <td>morning market losers</td>\n",
              "      <td>(Token: 1 morning, Token: 2 market, Token: 3 l...</td>\n",
              "      <td>0.999858</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555722</th>\n",
              "      <td>Mid-Morning Market Update: Markets Open Lower;...</td>\n",
              "      <td>2016-06-10</td>\n",
              "      <td>GNW</td>\n",
              "      <td>mid morning market update  markets open lower ...</td>\n",
              "      <td>(Token: 1 mid, Token: 2 morning, Token: 3 mark...</td>\n",
              "      <td>0.995033</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137174</th>\n",
              "      <td>Shares of several Brazilian bank stocks tradin...</td>\n",
              "      <td>2019-03-28</td>\n",
              "      <td>BBD</td>\n",
              "      <td>shares of several brazilian bank stocks tradin...</td>\n",
              "      <td>(Token: 1 shares, Token: 2 of, Token: 3 severa...</td>\n",
              "      <td>0.992516</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13092</th>\n",
              "      <td>Stocks Which Set New 52-Week Low Yesterday, Tu...</td>\n",
              "      <td>2018-12-20</td>\n",
              "      <td>ACM</td>\n",
              "      <td>stocks which set new    week low yesterday  tu...</td>\n",
              "      <td>(Token: 1 stocks, Token: 2 which, Token: 3 set...</td>\n",
              "      <td>0.999571</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bb1f8b3-350c-4f68-bba5-7503fcfe6298')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2bb1f8b3-350c-4f68-bba5-7503fcfe6298 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2bb1f8b3-350c-4f68-bba5-7503fcfe6298');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                     title  ...     value\n",
              "336161   Diebold's Planned Acquisition Of Wincor Nixdor...  ...  POSITIVE\n",
              "570059   Atlantic Equities Downgrades Garmin to Neutral...  ...  NEGATIVE\n",
              "1264993  TherapeuticsMD Reports Resubmission Of NDA For...  ...  POSITIVE\n",
              "478804   FAA To Streamline Fire Regulations For Cargo C...  ...  POSITIVE\n",
              "1232600           Earnings Scheduled For February 25, 2014  ...  POSITIVE\n",
              "...                                                    ...  ...       ...\n",
              "1036042  American Petro-Hunter's Sacramento Gas Project...  ...  POSITIVE\n",
              "1119241                             Morning Market Losers   ...  NEGATIVE\n",
              "555722   Mid-Morning Market Update: Markets Open Lower;...  ...  NEGATIVE\n",
              "137174   Shares of several Brazilian bank stocks tradin...  ...  POSITIVE\n",
              "13092    Stocks Which Set New 52-Week Low Yesterday, Tu...  ...  NEGATIVE\n",
              "\n",
              "[1000 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FinBERT\n",
        "\n",
        "*   Original BERT training Data English Wikipedia and BookCorpus (Zhu et al., 2015)\n",
        "*   Finance Articles from Yahoo Finance\n",
        "*   Financial News from Financial Web\n",
        "*   Question-Answer pairs about financial issues from Reddit"
      ],
      "metadata": {
        "id": "iLYuuZoyVt5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone',num_labels=3)\n",
        "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')"
      ],
      "metadata": {
        "id": "k4bn2uwmUe5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {0:'neutral', 1:'positive',2:'negative'}"
      ],
      "metadata": {
        "id": "HERK-dZDUjxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['text_obj_finBERT'] = data['text_clean'].apply(lambda x : tokenizer(x, return_tensors=\"pt\", padding=True))\n",
        "data['text_obj_finBERT'].apply(lambda x : finbert(**inputs)[0])\n",
        "data['sentiment_finBERT'] = data['text_obj_finBERT'].apply(lambda x : labels[np.argmax(x.detach().numpy())]"
      ],
      "metadata": {
        "id": "nfgNNwJOUlNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Financial News Analysis"
      ],
      "metadata": {
        "id": "u7tBTH9U6LPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "metadata": {
        "id": "wqrgdw9mLh3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_cleaner(text):\n",
        "    newString = text.lower()\n",
        "    newString = re.sub('\"', '', newString)\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(' ')])\n",
        "    newString = re.sub(r\"(?i)http(s):\\/\\/[a-z0-9.~_\\-\\/]+\", '', newString)\n",
        "    newString = re.sub(r\"(?i)@[a-z0-9_]+\", '', newString)\n",
        "    newString = re.sub('[^a-zA-Z\\s]', ' ', newString)\n",
        "    # tokens = [w for w in newString.split() if w not in stopwords]\n",
        "\n",
        "    return newString"
      ],
      "metadata": {
        "id": "cqXpi1we6qrb"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}