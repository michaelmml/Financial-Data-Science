{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinancialAnalysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMCkJfoiiZQa877nT3U88sW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michaelmml/Financial-Data-Science/blob/main/FinancialAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Twitter Dataset with API\n",
        "\n",
        "Twitter offers the past seven days of data on their free API tier, so we will go back in 60-minute windows and extract ~100 tweets from within each of these windows. Requires bearer tokens as from registration process with Twitter for developer access."
      ],
      "metadata": {
        "id": "ZtfboBIx3sg5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqfUR0P12Ml6"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('bearer_token.txt') as fp:\n",
        "    BEARER_TOKEN = fp.read()"
      ],
      "metadata": {
        "id": "N9snpVG037y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = 'https://api.twitter.com/2/tweets/search/recent'\n",
        "headers = {'authorization': f'Bearer {BEARER_TOKEN}'}\n",
        "params = {\n",
        "    'query': '(amazon OR aws OR jeff bezos) (lang:en)',\n",
        "    'max_results': '100',\n",
        "    'tweet.fields': 'created_at, lang'}"
      ],
      "metadata": {
        "id": "RQGqeGog38nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtformat = '%Y-%m-%dT%H:%M:%SZ'"
      ],
      "metadata": {
        "id": "3wdzCcAQ3_44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def time_periods(now, mins):\n",
        "    now = datetime.strptime(now, dtformat)\n",
        "    intervals_time = now - timedelta(minutes=mins) # time series at mins intervals\n",
        "    return intervals_time.strftime(dtformat)"
      ],
      "metadata": {
        "id": "ldE7kOf34HxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "now = datetime.now()  # get the current datetime, this is our starting point\n",
        "last_week = now - timedelta(days=7)  # datetime one week ago = the finish line\n",
        "now = now.strftime(dtformat)  # convert now datetime to format for API"
      ],
      "metadata": {
        "id": "4yd5CqhO5Qo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()"
      ],
      "metadata": {
        "id": "B9hX5I3O5hiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def twitter_data(tweet):\n",
        "    data = {\n",
        "        'id': tweet['id_str'],\n",
        "        'created_at': tweet['created_at'],\n",
        "        'text': tweet['full_text']\n",
        "    }\n",
        "    return data"
      ],
      "metadata": {
        "id": "kp9T0lb154l9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    if datetime.strptime(now, dtformat) < last_week:\n",
        "        break # loop based on earliest time\n",
        "      \n",
        "    pre60 = time_periods(now, 60)\n",
        "    params['start_time'] = pre60\n",
        "    params['end_time'] = now\n",
        "    response = requests.get(endpoint,\n",
        "                            params=params,\n",
        "                            headers=headers)\n",
        "    now = pre60\n",
        "\n",
        "    for tweet in response.json()['data']:\n",
        "        row = twitter_data(tweet)\n",
        "        df = df.append(row, ignore_index=True)"
      ],
      "metadata": {
        "id": "5BMaXIIZ5jEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Beautiful Soup\n",
        "\n",
        "Extraction from websites based on html format - e.g. see code referring to find_all by class. Understand structure of website and develop code for that."
      ],
      "metadata": {
        "id": "BdjuDk6ZWVR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR REFERENCE\n",
        "seed_urls = ['https://inshorts.com/en/read/financial']\n",
        "\n",
        "def build_dataset(seed_urls):\n",
        "    news_data = []\n",
        "    for url in seed_urls:\n",
        "        news_category = url.split('/')[-1]\n",
        "        data = requests.get(url)\n",
        "        soup = BeautifulSoup(data.content, 'html.parser')\n",
        "        \n",
        "        news_articles = [{'news_headline': headline.find('span', \n",
        "                                                         attrs={\"itemprop\": \"headline\"}).string,\n",
        "                          'news_article': article.find('div', \n",
        "                                                       attrs={\"itemprop\": \"articleBody\"}).string,\n",
        "                          'news_category': news_category}\n",
        "                         \n",
        "                            for headline, article in \n",
        "                             zip(soup.find_all('div', \n",
        "                                               class_=[\"news-card-title news-right-box\"]),\n",
        "                                 soup.find_all('div', \n",
        "                                               class_=[\"news-card-content news-right-box\"]))\n",
        "                        ]\n",
        "        news_data.extend(news_articles)\n",
        "        \n",
        "    df =  pd.DataFrame(news_data)\n",
        "    df = df[['news_headline', 'news_article', 'news_category']]\n",
        "    return df"
      ],
      "metadata": {
        "id": "kLi9RqXXWUnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gathering Financial News / Sentiment Analysis with BERT\n",
        "\n",
        "Historical analyst headlines and financial news headlines over several years on a sample of listed companies. Sentiment analysis using flair; classification into positive / negative with probability."
      ],
      "metadata": {
        "id": "MGjRAMPl-XbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFi8tvBp-ah_",
        "outputId": "2cb46ac2-fd48-443f-e1a1-a325d4e868e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_folder='/content/drive/My Drive/DataAnalysis'"
      ],
      "metadata": {
        "id": "eM7qcZRk-ukO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(root_folder+'/analyst_ratings_processed.csv')\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJU72hoM-wG0",
        "outputId": "6a189f30-99b4-4402-e75f-95e9ff6ea435"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1400469 entries, 0 to 1400468\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count    Dtype  \n",
            "---  ------      --------------    -----  \n",
            " 0   Unnamed: 0  1399180 non-null  float64\n",
            " 1   title       1400469 non-null  object \n",
            " 2   date        1399180 non-null  object \n",
            " 3   stock       1397891 non-null  object \n",
            "dtypes: float64(1), object(3)\n",
            "memory usage: 42.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.dropna(axis=0)"
      ],
      "metadata": {
        "id": "MG5oPhfSEZdx"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['date'] = data['date'].str.split(' ').str[0]\n",
        "data['date'] = pd.Series(pd.to_datetime(data['date'], format='%Y-%m-%d')) # 2020-06-05 10:30:00-04:00"
      ],
      "metadata": {
        "id": "Oo5PU8G--0g7"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop('Unnamed: 0', axis=1)"
      ],
      "metadata": {
        "id": "9whjL_wOE1Rf"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flair / DistilBERT\n",
        "\n",
        "This model splits the text into character-level tokens and uses the DistilBERT model to make predictions.The advantage of working at the character-level (as opposed to word-level) is that words that the network has never seen before can still be assigned a sentiment. DistilBERT is a distilled version of the powerful BERT transformer model"
      ],
      "metadata": {
        "id": "X6WNF9WKIhmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import flair\n",
        "sentiment_model = flair.models.TextClassifier.load('en-sentiment')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5upNGYmGy1g",
        "outputId": "52824632-1986-458c-a920-29faf050e359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-20 22:01:09,439 loading file /root/.flair/models/sentiment-en-mix-distillbert_4.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.sample(n = 1000, replace = False)\n",
        "data['text_clean'] = data['title'].apply(lambda x : text_cleaner(x))"
      ],
      "metadata": {
        "id": "b0annuv0HURZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['text_obj'] = data['text_clean'].apply(lambda x : flair.data.Sentence(x))\n",
        "data['text_obj'].apply(lambda x : sentiment_model.predict(x))\n",
        "data['score'] = data['text_obj'].apply(lambda x : x.labels[0].score)\n",
        "data['value'] = data['text_obj'].apply(lambda x : x.labels[0].value)"
      ],
      "metadata": {
        "id": "anCXBuwRHpTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "id": "2TJ3n2RiLPs6",
        "outputId": "697a88ea-afae-4f20-f47c-fe28326727ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2bb1f8b3-350c-4f68-bba5-7503fcfe6298\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>date</th>\n",
              "      <th>stock</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_obj</th>\n",
              "      <th>score</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>336161</th>\n",
              "      <td>Diebold's Planned Acquisition Of Wincor Nixdor...</td>\n",
              "      <td>2016-05-31</td>\n",
              "      <td>DBD</td>\n",
              "      <td>diebold s planned acquisition of wincor nixdor...</td>\n",
              "      <td>(Token: 1 diebold, Token: 2 s, Token: 3 planne...</td>\n",
              "      <td>0.556393</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570059</th>\n",
              "      <td>Atlantic Equities Downgrades Garmin to Neutral...</td>\n",
              "      <td>2015-02-20</td>\n",
              "      <td>GRMN</td>\n",
              "      <td>atlantic equities downgrades garmin to neutral...</td>\n",
              "      <td>(Token: 1 atlantic, Token: 2 equities, Token: ...</td>\n",
              "      <td>0.998690</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1264993</th>\n",
              "      <td>TherapeuticsMD Reports Resubmission Of NDA For...</td>\n",
              "      <td>2017-11-29</td>\n",
              "      <td>TXMD</td>\n",
              "      <td>therapeuticsmd reports resubmission of nda for...</td>\n",
              "      <td>(Token: 1 therapeuticsmd, Token: 2 reports, To...</td>\n",
              "      <td>0.984767</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>478804</th>\n",
              "      <td>FAA To Streamline Fire Regulations For Cargo C...</td>\n",
              "      <td>2019-07-03</td>\n",
              "      <td>FDX</td>\n",
              "      <td>faa to streamline fire regulations for cargo c...</td>\n",
              "      <td>(Token: 1 faa, Token: 2 to, Token: 3 streamlin...</td>\n",
              "      <td>0.790327</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1232600</th>\n",
              "      <td>Earnings Scheduled For February 25, 2014</td>\n",
              "      <td>2014-02-25</td>\n",
              "      <td>TOL</td>\n",
              "      <td>earnings scheduled for february</td>\n",
              "      <td>(Token: 1 earnings, Token: 2 scheduled, Token:...</td>\n",
              "      <td>0.872605</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1036042</th>\n",
              "      <td>American Petro-Hunter's Sacramento Gas Project...</td>\n",
              "      <td>2009-08-10</td>\n",
              "      <td>Q</td>\n",
              "      <td>american petro hunter s sacramento gas project...</td>\n",
              "      <td>(Token: 1 american, Token: 2 petro, Token: 3 h...</td>\n",
              "      <td>0.612436</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1119241</th>\n",
              "      <td>Morning Market Losers</td>\n",
              "      <td>2013-06-10</td>\n",
              "      <td>SHI</td>\n",
              "      <td>morning market losers</td>\n",
              "      <td>(Token: 1 morning, Token: 2 market, Token: 3 l...</td>\n",
              "      <td>0.999858</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555722</th>\n",
              "      <td>Mid-Morning Market Update: Markets Open Lower;...</td>\n",
              "      <td>2016-06-10</td>\n",
              "      <td>GNW</td>\n",
              "      <td>mid morning market update  markets open lower ...</td>\n",
              "      <td>(Token: 1 mid, Token: 2 morning, Token: 3 mark...</td>\n",
              "      <td>0.995033</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137174</th>\n",
              "      <td>Shares of several Brazilian bank stocks tradin...</td>\n",
              "      <td>2019-03-28</td>\n",
              "      <td>BBD</td>\n",
              "      <td>shares of several brazilian bank stocks tradin...</td>\n",
              "      <td>(Token: 1 shares, Token: 2 of, Token: 3 severa...</td>\n",
              "      <td>0.992516</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13092</th>\n",
              "      <td>Stocks Which Set New 52-Week Low Yesterday, Tu...</td>\n",
              "      <td>2018-12-20</td>\n",
              "      <td>ACM</td>\n",
              "      <td>stocks which set new    week low yesterday  tu...</td>\n",
              "      <td>(Token: 1 stocks, Token: 2 which, Token: 3 set...</td>\n",
              "      <td>0.999571</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bb1f8b3-350c-4f68-bba5-7503fcfe6298')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2bb1f8b3-350c-4f68-bba5-7503fcfe6298 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2bb1f8b3-350c-4f68-bba5-7503fcfe6298');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                     title  ...     value\n",
              "336161   Diebold's Planned Acquisition Of Wincor Nixdor...  ...  POSITIVE\n",
              "570059   Atlantic Equities Downgrades Garmin to Neutral...  ...  NEGATIVE\n",
              "1264993  TherapeuticsMD Reports Resubmission Of NDA For...  ...  POSITIVE\n",
              "478804   FAA To Streamline Fire Regulations For Cargo C...  ...  POSITIVE\n",
              "1232600           Earnings Scheduled For February 25, 2014  ...  POSITIVE\n",
              "...                                                    ...  ...       ...\n",
              "1036042  American Petro-Hunter's Sacramento Gas Project...  ...  POSITIVE\n",
              "1119241                             Morning Market Losers   ...  NEGATIVE\n",
              "555722   Mid-Morning Market Update: Markets Open Lower;...  ...  NEGATIVE\n",
              "137174   Shares of several Brazilian bank stocks tradin...  ...  POSITIVE\n",
              "13092    Stocks Which Set New 52-Week Low Yesterday, Tu...  ...  NEGATIVE\n",
              "\n",
              "[1000 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FinBERT\n",
        "\n",
        "*   Original BERT training Data English Wikipedia and BookCorpus (Zhu et al., 2015)\n",
        "*   Finance Articles from Yahoo Finance\n",
        "*   Financial News from Financial Web\n",
        "*   Question-Answer pairs about financial issues from Reddit"
      ],
      "metadata": {
        "id": "iLYuuZoyVt5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone',num_labels=3)\n",
        "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')"
      ],
      "metadata": {
        "id": "k4bn2uwmUe5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {0:'neutral', 1:'positive',2:'negative'}"
      ],
      "metadata": {
        "id": "HERK-dZDUjxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['text_obj_finBERT'] = data['text_clean'].apply(lambda x : tokenizer(x, return_tensors=\"pt\", padding=True))\n",
        "data['text_obj_finBERT'].apply(lambda x : finbert(**inputs)[0])\n",
        "data['sentiment_finBERT'] = data['text_obj_finBERT'].apply(lambda x : labels[np.argmax(x.detach().numpy())]"
      ],
      "metadata": {
        "id": "nfgNNwJOUlNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Financial News Analysis\n",
        "\n",
        "**Text-wranging and pre-processing.** Approached from a detailed perspective in contraction mapping, lemmatisation and stemming. Aim to standardise corpus and minimise vocabulary size for deep learning models or extractive techniques."
      ],
      "metadata": {
        "id": "u7tBTH9U6LPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "metadata": {
        "id": "wqrgdw9mLh3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_cleaner(text):\n",
        "    newString = text.lower()\n",
        "    newString = re.sub('\"', '', newString)\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(' ')])\n",
        "    newString = re.sub(r\"(?i)http(s):\\/\\/[a-z0-9.~_\\-\\/]+\", '', newString)\n",
        "    newString = re.sub(r\"(?i)@[a-z0-9_]+\", '', newString)\n",
        "    newString = re.sub('[^a-zA-Z\\s]', ' ', newString)\n",
        "\n",
        "    return newString"
      ],
      "metadata": {
        "id": "cqXpi1we6qrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "General cleaning technique above based on regex. e.g. r\"(?i)http(s):\\/\\/[a-z0-9.~_\\-\\/]+\" removes all such special characters. And final cleaning function to remove all non alpha-numerical characters. Only requires care in certain special characters needing to be replaced by space (e.g. \"-\") and others by BLANK."
      ],
      "metadata": {
        "id": "ciqxdrwiXgHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import unicodedata"
      ],
      "metadata": {
        "id": "ZmRdw2VaXYQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def strip_html_tags(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    stripped_text = soup.get_text()\n",
        "    return stripped_text"
      ],
      "metadata": {
        "id": "JLV7xmyaW7sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_accented_chars(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return text"
      ],
      "metadata": {
        "id": "hZ9FMqr1XdlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word stems** are also known as the base form of a word, and we can create new words by attaching affixes to them in a process known as inflection."
      ],
      "metadata": {
        "id": "I2sL-m1WYJ4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_stemmer(text):\n",
        "    ps = nltk.porter.PorterStemmer()\n",
        "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
        "    return text"
      ],
      "metadata": {
        "id": "DufvwMFfYLEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemmatization** is very similar to stemming, where we remove word affixes to get to the base form of a word. However, the base form in this case is known as the root word, but not the root stem. The difference being that the root word is always a lexicographically correct word"
      ],
      "metadata": {
        "id": "5eBoT2xwYNFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_text(text):\n",
        "    text = nlp(text)\n",
        "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
        "    return text"
      ],
      "metadata": {
        "id": "bT0Y3qDCYUoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stopwords** - typically, these can be articles, conjunctions, prepositions and so on. Some examples of stopwords are a, an, the, and the like."
      ],
      "metadata": {
        "id": "oTo8FNFUYcF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords_shortwords(text, length):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
        "\n",
        "    long_words = []\n",
        "    prev_word = []\n",
        "    for i in filtered_tokens:\n",
        "        if i not in prev_word and len(i) >= length:\n",
        "            long_words.append(i)\n",
        "            prev_word = [i]    \n",
        "    return (\" \".join(long_words)).strip()"
      ],
      "metadata": {
        "id": "7bFbelYXYWOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**General function** to combine preprocessing steps. Also important to be able to toggle functions as for part-of-speech analysis, we **do not want to lower case text** or lemmatize/stem due to the change in grammatical structure."
      ],
      "metadata": {
        "id": "z9y-eHQMZ4HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_corpus(corpus, html_stripping=True,\n",
        "                     accented_char_removal=True, text_lower_case=True, \n",
        "                     text_lemmatization=True, simple_stemmer=True, \n",
        "                     remove_stopwords_shortwords=True):\n",
        "    \n",
        "    normalized_corpus = []\n",
        "\n",
        "    for doc in corpus:\n",
        "        if html_stripping:\n",
        "            doc = strip_html_tags(doc)\n",
        "        if accented_char_removal:\n",
        "            doc = remove_accented_chars(doc)  \n",
        "        if text_lower_case:\n",
        "            doc = doc.lower()\n",
        "        if text_lemmatization:\n",
        "            doc = lemmatize_text(doc)\n",
        "        if simple_stemmer:\n",
        "            doc = simple_stemmer(doc)\n",
        "        if remove_stopwords_shortwords:\n",
        "            doc = remove_stopwords_shortwords(doc)\n",
        "        # remove extra newlines\n",
        "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
        "        normalized_corpus.append(doc)\n",
        "    \n",
        "    return normalized_corpus"
      ],
      "metadata": {
        "id": "RojaBZ6XZCnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Language Syntax and Structure"
      ],
      "metadata": {
        "id": "7LFaX9BoaEhk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**N(oun)**: This usually denotes words that depict some object or entity, which may be living or nonliving.\n",
        "\n",
        "**V(erb)**: Verbs are words that are used to describe certain actions, states, or occurrences. There are a wide variety of further subcategories, such as auxiliary, reflexive, and transitive verbs (and many more).\n",
        "\n",
        "**Adj(ective)**: Adjectives are words used to describe or qualify other words, typically nouns and noun phrases. The POS tag symbol for adjectives is ADJ.\n",
        "\n",
        "**Adv(erb)**: Adverbs usually act as modifiers for other words including nouns, adjectives, verbs, or other adverbs. The phrase very beautiful flower has the adverb (ADV) very, which modifies the adjective (ADJ) beautiful , indicating the degree to which the flower is beautiful. The POS tag symbol for adverbs is ADV.\n",
        "\n",
        "Further include pronouns, prepositions, interjections, conjunctions, determiners, and many others. Plus each POS tag like the noun (N) can be further subdivided into categories like singular nouns (NN), singular proper nouns (NNP), and plural nouns (NNS)."
      ],
      "metadata": {
        "id": "0MOsz_RLaKEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = normalize_corpus(data['title'], text_lower_case=False, \n",
        "                          text_lemmatization=False, simple_stemmer=False, remove_stopwords_shortwords=False)\n",
        "\n",
        "# Example\n",
        "sentence = str(data.iloc[1].title)\n",
        "sentence_nlp = nlp(sentence)\n",
        "\n",
        "# POS tagging with Spacy \n",
        "spacy_pos_tagged = [(word, word.tag_, word.pos_) for word in sentence_nlp]\n",
        "pd.DataFrame(spacy_pos_tagged, columns=['Word', 'POS tag', 'Tag type'])\n",
        "\n",
        "# POS tagging with nltk\n",
        "nltk_pos_tagged = nltk.pos_tag(sentence.split())\n",
        "pd.DataFrame(nltk_pos_tagged, columns=['Word', 'POS tag'])"
      ],
      "metadata": {
        "id": "t5KI7aCZZ3af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shallow Parsing\n",
        "\n",
        "Noun phrase (NP): These are phrases where a noun acts as the head word. Noun phrases act as a subject or object to a verb.\n",
        "\n",
        "Verb phrase (VP): These phrases are lexical units that have a verb acting as the head word. Usually, there are two forms of verb phrases. One form has the verb components as well as other entities such as nouns, adjectives, or adverbs as parts of the object.\n",
        "\n",
        "Adjective phrase (ADJP): These are phrases with an adjective as the head word. Their main role is to describe or qualify nouns and pronouns in a sentence, and they will be either placed before or after the noun or pronoun.\n",
        "\n",
        "Adverb phrase (ADVP): These phrases act like adverbs since the adverb acts as the head word in the phrase. Adverb phrases are used as modifiers for nouns, verbs, or adverbs themselves by providing further details that describe or qualify them.\n",
        "\n",
        "Prepositional phrase (PP): These phrases usually contain a preposition as the head word and other lexical components like nouns, pronouns, and so on. These act like an adjective or adverb describing other words or phrases."
      ],
      "metadata": {
        "id": "Bvd1_WaVdUPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('conll2000')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6zl2_RPYOQF",
        "outputId": "68feacbb-1a36-4fc4-fb8c-5f1c99afb25c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_Ku3-NwZxIj",
        "outputId": "16a2c112-ac75-4571-a396-94c30c656cdd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import conll2000\n",
        "\n",
        "data = conll2000.chunked_sents()\n",
        "train_data = data[:10900]\n",
        "test_data = data[10900:] \n",
        "\n",
        "print(len(train_data), len(test_data))\n",
        "print(train_data[1]) "
      ],
      "metadata": {
        "id": "E47AO8fuctfo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fce3e74b-e43f-40e0-8516-e4be2632a3fa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10900 48\n",
            "(S\n",
            "  Chancellor/NNP\n",
            "  (PP of/IN)\n",
            "  (NP the/DT Exchequer/NNP)\n",
            "  (NP Nigel/NNP Lawson/NNP)\n",
            "  (NP 's/POS restated/VBN commitment/NN)\n",
            "  (PP to/TO)\n",
            "  (NP a/DT firm/NN monetary/JJ policy/NN)\n",
            "  (VP has/VBZ helped/VBN to/TO prevent/VB)\n",
            "  (NP a/DT freefall/NN)\n",
            "  (PP in/IN)\n",
            "  (NP sterling/NN)\n",
            "  (PP over/IN)\n",
            "  (NP the/DT past/JJ week/NN)\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two chunking utility functions, tree2conlltags , to get triples of word, tag, and chunk tags for each token, and conlltags2tree to generate a parse tree from these token triples. The chunk tags use the IOB format. This notation represents Inside, Outside, and Beginning. The B- prefix before a tag indicates it is the beginning of a chunk, and I- prefix indicates that it is inside a chunk. The O tag indicates that the token does not belong to any chunk. The B- tag is always used when there are subsequent tags of the same type following it without the presence of O tags between them."
      ],
      "metadata": {
        "id": "EO7KC1SjYcgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.chunk.util import tree2conlltags, conlltags2tree\n",
        "\n",
        "wtc = tree2conlltags(train_data[1])\n",
        "wtc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAWJVtouYTBp",
        "outputId": "29d61cb5-ace1-4caf-fc2a-7a07c2c9461a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Chancellor', 'NNP', 'O'),\n",
              " ('of', 'IN', 'B-PP'),\n",
              " ('the', 'DT', 'B-NP'),\n",
              " ('Exchequer', 'NNP', 'I-NP'),\n",
              " ('Nigel', 'NNP', 'B-NP'),\n",
              " ('Lawson', 'NNP', 'I-NP'),\n",
              " (\"'s\", 'POS', 'B-NP'),\n",
              " ('restated', 'VBN', 'I-NP'),\n",
              " ('commitment', 'NN', 'I-NP'),\n",
              " ('to', 'TO', 'B-PP'),\n",
              " ('a', 'DT', 'B-NP'),\n",
              " ('firm', 'NN', 'I-NP'),\n",
              " ('monetary', 'JJ', 'I-NP'),\n",
              " ('policy', 'NN', 'I-NP'),\n",
              " ('has', 'VBZ', 'B-VP'),\n",
              " ('helped', 'VBN', 'I-VP'),\n",
              " ('to', 'TO', 'I-VP'),\n",
              " ('prevent', 'VB', 'I-VP'),\n",
              " ('a', 'DT', 'B-NP'),\n",
              " ('freefall', 'NN', 'I-NP'),\n",
              " ('in', 'IN', 'B-PP'),\n",
              " ('sterling', 'NN', 'B-NP'),\n",
              " ('over', 'IN', 'B-PP'),\n",
              " ('the', 'DT', 'B-NP'),\n",
              " ('past', 'JJ', 'I-NP'),\n",
              " ('week', 'NN', 'I-NP'),\n",
              " ('.', '.', 'O')]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conll_tag_chunks(chunk_sents):\n",
        "    tagged_sents = [tree2conlltags(tree) for tree in chunk_sents]\n",
        "    return [[(t, c) for (w, t, c) in sent] for sent in tagged_sents]"
      ],
      "metadata": {
        "id": "3Bv63TrvYgXS"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combined_tagger(train_data, taggers, backoff=None):\n",
        "    for tagger in taggers:\n",
        "        backoff = tagger(train_data, backoff=backoff)\n",
        "    return backoff "
      ],
      "metadata": {
        "id": "Dh-k3exmZAIV"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag import UnigramTagger, BigramTagger\n",
        "from nltk.chunk import ChunkParserI\n",
        "\n",
        "# define the chunker class\n",
        "class NGramTagChunker(ChunkParserI):\n",
        "    \n",
        "  def __init__(self, train_sentences, \n",
        "               tagger_classes=[UnigramTagger, BigramTagger]):\n",
        "    train_sent_tags = conll_tag_chunks(train_sentences)\n",
        "    self.chunk_tagger = combined_tagger(train_sent_tags, tagger_classes)\n",
        "\n",
        "  def parse(self, tagged_sentence):\n",
        "    if not tagged_sentence: \n",
        "        return None\n",
        "    pos_tags = [tag for word, tag in tagged_sentence]\n",
        "    chunk_pos_tags = self.chunk_tagger.tag(pos_tags)\n",
        "    chunk_tags = [chunk_tag for (pos_tag, chunk_tag) in chunk_pos_tags]\n",
        "    wpc_tags = [(word, pos_tag, chunk_tag) for ((word, pos_tag), chunk_tag)\n",
        "                     in zip(tagged_sentence, chunk_tags)]\n",
        "    return conlltags2tree(wpc_tags)\n",
        "  \n",
        "# train chunker model  \n",
        "ntc = NGramTagChunker(train_data)\n",
        "\n",
        "# evaluate chunker model performance\n",
        "print(ntc.evaluate(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CimedE8yZJvn",
        "outputId": "24fc8a97-71ea-480f-f8b8-3c18d8b995a7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChunkParse score:\n",
            "    IOB Accuracy:  90.0%%\n",
            "    Precision:     82.1%%\n",
            "    Recall:        86.3%%\n",
            "    F-Measure:     84.1%%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = str(data.iloc[1].title)\n",
        "nltk_pos_tagged = nltk.pos_tag(sentence.split())\n",
        "pd.DataFrame(nltk_pos_tagged, columns=['Word', 'POS tag'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "YOhsSF2zZLT4",
        "outputId": "b93c5e15-6d5f-41df-cda3-5675fc195528"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b2802f04-0d1d-4fcc-8542-e56d406f62ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>POS tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stocks</td>\n",
              "      <td>NNS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>That</td>\n",
              "      <td>WDT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hit</td>\n",
              "      <td>VBP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>52-Week</td>\n",
              "      <td>JJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Highs</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>On</td>\n",
              "      <td>IN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Wednesday</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2802f04-0d1d-4fcc-8542-e56d406f62ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b2802f04-0d1d-4fcc-8542-e56d406f62ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b2802f04-0d1d-4fcc-8542-e56d406f62ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        Word POS tag\n",
              "0     Stocks     NNS\n",
              "1       That     WDT\n",
              "2        Hit     VBP\n",
              "3    52-Week      JJ\n",
              "4      Highs     NNP\n",
              "5         On      IN\n",
              "6  Wednesday     NNP"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_tree = ntc.parse(nltk_pos_tagged)\n",
        "print(chunk_tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmAdEMSzZ6PA",
        "outputId": "defc8317-0d9a-4522-a211-ead71d32937a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP Stocks/NNS)\n",
            "  (NP That/WDT)\n",
            "  (VP Hit/VBP)\n",
            "  (NP 52-Week/JJ Highs/NNP)\n",
            "  (PP On/IN)\n",
            "  (NP Wednesday/NNP))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constituency Parsing\n",
        "\n",
        "Constituent-based grammars are used to analyze and determine the constituents of a sentence. These grammars can be used to model or represent the internal structure of sentences in terms of a hierarchically ordered structure of their constituents. The Stanford parser generally uses a PCFG (probabilistic context-free grammar) parser. A PCFG is a context-free grammar that associates a probability with each of its production rules."
      ],
      "metadata": {
        "id": "bOG2E2TiaVL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.parse.stanford import StanfordParser\n",
        "\n",
        "scp = StanfordParser(path_to_jar='E:/stanford/stanford-parser-full-2015-04-20/stanford-parser.jar',\n",
        "                     path_to_models_jar='E:/stanford/stanford-parser-full-2015-04-20/stanford-parser-3.5.2-models.jar')\n",
        "                   \n",
        "result = list(scp.raw_parse(sentence))\n",
        "print(result[0])"
      ],
      "metadata": {
        "id": "eznvAXf6aVyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependency Parsing\n",
        "\n",
        "Both structure and semantic dependencies and relationships between tokens in a sentence.\n",
        "\n",
        "The dependency tag det is pretty intuitive — it denotes the determiner relationship between a nominal head and the determiner. Usually, the word with POS tag DET will also have the det dependency tag relation. Examples include fox → the and dog → the.\n",
        "\n",
        "The dependency tag amod stands for adjectival modifier and stands for any adjective that modifies the meaning of a noun. Examples include fox → brown and dog → lazy.\n",
        "\n",
        "The dependency tag nsubj stands for an entity that acts as a subject or agent in a clause. Examples include is → fox and jumping → he.\n",
        "The dependencies cc and conj have more to do with linkages related to words connected by coordinating conjunctions . Examples include is → and and is → jumping.\n",
        "\n",
        "The dependency tag aux indicates the auxiliary or secondary verb in the clause. Example: jumping → is.\n",
        "\n",
        "The dependency tag acomp stands for adjective complement and acts as the complement or object to a verb in the sentence. Example: is → quick\n",
        "The dependency tag prep denotes a prepositional modifier, which usually modifies the meaning of a noun, verb, adjective, or preposition. Usually, this representation is used for prepositions having a noun or noun phrase complement. Example: jumping → over.\n",
        "\n",
        "The dependency tag pobj is used to denote the object of a preposition . This is usually the head of a noun phrase following a preposition in the sentence. Example: over → dog."
      ],
      "metadata": {
        "id": "kKifPyVVay-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "kO1SbopIbJvW"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_nlp = nlp(sentence)"
      ],
      "metadata": {
        "id": "3tOrAqHebHj2"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dependency_pattern = '{left}<---{word}[{w_type}]--->{right}\\n--------'\n",
        "for token in sentence_nlp:\n",
        "    print(dependency_pattern.format(word=token.orth_, \n",
        "                                  w_type=token.dep_,\n",
        "                                  left=[t.orth_ \n",
        "                                            for t \n",
        "                                            in token.lefts],\n",
        "                                  right=[t.orth_ \n",
        "                                             for t \n",
        "                                             in token.rights]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dwzdkqk-aw5k",
        "outputId": "562cddb6-4334-42aa-c077-d9923e049fff"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]<---Stocks[ROOT]--->['Hit']\n",
            "--------\n",
            "[]<---That[nsubj]--->[]\n",
            "--------\n",
            "['That']<---Hit[relcl]--->['Highs', 'On']\n",
            "--------\n",
            "[]<---52-Week[nummod]--->[]\n",
            "--------\n",
            "['52-Week']<---Highs[dobj]--->[]\n",
            "--------\n",
            "[]<---On[prep]--->['Wednesday']\n",
            "--------\n",
            "[]<---Wednesday[pobj]--->[]\n",
            "--------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "\n",
        "displacy.render(sentence_nlp, jupyter=True, \n",
        "                options={'distance': 110,\n",
        "                         'arrow_stroke': 2,\n",
        "                         'arrow_width': 8})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "KWEeA0nKbTNR",
        "outputId": "9dfad789-04e7-4628-ce2f-8ad252d44c42"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"7b051987beb14d95b42cbdc11de262b8-0\" class=\"displacy\" width=\"820\" height=\"302.0\" direction=\"ltr\" style=\"max-width: none; height: 302.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Stocks</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">That</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">Hit</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">52-Week</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">Highs</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">On</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">Wednesday</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-7b051987beb14d95b42cbdc11de262b8-0-0\" stroke-width=\"2px\" d=\"M180,167.0 C180,112.0 260.0,112.0 260.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-7b051987beb14d95b42cbdc11de262b8-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M180,169.0 L174,159.0 186,159.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-7b051987beb14d95b42cbdc11de262b8-0-1\" stroke-width=\"2px\" d=\"M70,167.0 C70,57.0 265.0,57.0 265.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-7b051987beb14d95b42cbdc11de262b8-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M265.0,169.0 L271.0,159.0 259.0,159.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-7b051987beb14d95b42cbdc11de262b8-0-2\" stroke-width=\"2px\" d=\"M400,167.0 C400,112.0 480.0,112.0 480.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-7b051987beb14d95b42cbdc11de262b8-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M400,169.0 L394,159.0 406,159.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-7b051987beb14d95b42cbdc11de262b8-0-3\" stroke-width=\"2px\" d=\"M290,167.0 C290,57.0 485.0,57.0 485.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-7b051987beb14d95b42cbdc11de262b8-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M485.0,169.0 L491.0,159.0 479.0,159.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-7b051987beb14d95b42cbdc11de262b8-0-4\" stroke-width=\"2px\" d=\"M290,167.0 C290,2.0 600.0,2.0 600.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-7b051987beb14d95b42cbdc11de262b8-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M600.0,169.0 L606.0,159.0 594.0,159.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-7b051987beb14d95b42cbdc11de262b8-0-5\" stroke-width=\"2px\" d=\"M620,167.0 C620,112.0 700.0,112.0 700.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-7b051987beb14d95b42cbdc11de262b8-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M700.0,169.0 L706.0,159.0 694.0,159.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Named Entity Recognition"
      ],
      "metadata": {
        "id": "JE1DeVy4bbuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = str(data.iloc[5].title)\n",
        "sentence_nlp = nlp(sentence)\n",
        "\n",
        "print([(word, word.ent_type_) for word in sentence_nlp if word.ent_type_])\n",
        "\n",
        "displacy.render(sentence_nlp, style='ent', jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "TmRRTAHabWIN",
        "outputId": "ab3c109f-0901-4927-f0e5-94e4b76f037c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(Agilent, 'ORG'), (Technologies, 'ORG'), (85, 'MONEY')]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">CFRA Maintains Hold on \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Agilent Technologies\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", Lowers Price Target to $\n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    85\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              "</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = corpus[:1000]"
      ],
      "metadata": {
        "id": "7HAh2BNbjyZF"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "named_entities = []\n",
        "for sentence in corpus:\n",
        "    temp_entity_name = ''\n",
        "    temp_named_entity = None\n",
        "    sentence = nlp(sentence)\n",
        "    for word in sentence:\n",
        "        term = word.text\n",
        "        tag = word.ent_type_\n",
        "        if tag:\n",
        "            temp_entity_name = ' '.join([temp_entity_name, term]).strip()\n",
        "            temp_named_entity = (temp_entity_name, tag)\n",
        "        else:\n",
        "          if temp_named_entity:\n",
        "            named_entities.append(temp_named_entity)\n",
        "            temp_entity_name = ''\n",
        "            temp_named_entity = None\n",
        "      \n",
        "entity_frame = pd.DataFrame(named_entities, \n",
        "                            columns=['Entity Name', 'Entity Type'])"
      ],
      "metadata": {
        "id": "wvdWPCqDbt6D"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the top named entities\n",
        "top_entities = (entity_frame.groupby(by=['Entity Name', 'Entity Type'])\n",
        "                           .size()\n",
        "                           .sort_values(ascending=False)\n",
        "                           .reset_index().rename(columns={0 : 'Frequency'}))\n",
        "\n",
        "top_entities.T.iloc[:,:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "nbYgvPJpkER3",
        "outputId": "dd07042c-afba-4326-edba-af5c8349e90c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-574ee4a4-c4f7-43c9-93e6-9b19d207dfc6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Entity Name</th>\n",
              "      <td>52-Week</td>\n",
              "      <td>Agilent Technologies</td>\n",
              "      <td>US</td>\n",
              "      <td>EPS</td>\n",
              "      <td>China</td>\n",
              "      <td>UBS Maintains Neutral on Agilent Technologies</td>\n",
              "      <td>Benzinga 's Top Upgrades</td>\n",
              "      <td>85</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>Barclays Maintains Equal - Weight on Agilent T...</td>\n",
              "      <td>Friday</td>\n",
              "      <td>Adj</td>\n",
              "      <td>5.5B-$5.55B</td>\n",
              "      <td>3.38-$3.43</td>\n",
              "      <td>Q1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Entity Type</th>\n",
              "      <td>CARDINAL</td>\n",
              "      <td>ORG</td>\n",
              "      <td>GPE</td>\n",
              "      <td>ORG</td>\n",
              "      <td>GPE</td>\n",
              "      <td>ORG</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>MONEY</td>\n",
              "      <td>DATE</td>\n",
              "      <td>ORG</td>\n",
              "      <td>DATE</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>MONEY</td>\n",
              "      <td>MONEY</td>\n",
              "      <td>CARDINAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Frequency</th>\n",
              "      <td>14</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-574ee4a4-c4f7-43c9-93e6-9b19d207dfc6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-574ee4a4-c4f7-43c9-93e6-9b19d207dfc6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-574ee4a4-c4f7-43c9-93e6-9b19d207dfc6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                   0                     1   ...          13        14\n",
              "Entity Name   52-Week  Agilent Technologies  ...  3.38-$3.43        Q1\n",
              "Entity Type  CARDINAL                   ORG  ...       MONEY  CARDINAL\n",
              "Frequency          14                     8  ...           2         2\n",
              "\n",
              "[3 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# get the top named entity types\n",
        "top_entities = (entity_frame.groupby(by=['Entity Type'])\n",
        "                           .size()\n",
        "                           .sort_values(ascending=False)\n",
        "                           .reset_index().rename(columns={0 : 'Frequency'}))\n",
        "top_entities.T.iloc[:,:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "8_59IH5Kd0I8",
        "outputId": "acc148af-7681-4bb8-d75e-6174870c425f"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4209bcb3-dec3-40bd-9005-a1f2462b4321\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Entity Type</th>\n",
              "      <td>ORG</td>\n",
              "      <td>CARDINAL</td>\n",
              "      <td>MONEY</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>GPE</td>\n",
              "      <td>DATE</td>\n",
              "      <td>NORP</td>\n",
              "      <td>PERCENT</td>\n",
              "      <td>PRODUCT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Frequency</th>\n",
              "      <td>36</td>\n",
              "      <td>31</td>\n",
              "      <td>30</td>\n",
              "      <td>18</td>\n",
              "      <td>17</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4209bcb3-dec3-40bd-9005-a1f2462b4321')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4209bcb3-dec3-40bd-9005-a1f2462b4321 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4209bcb3-dec3-40bd-9005-a1f2462b4321');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "               0         1      2       3    4     5     6        7        8\n",
              "Entity Type  ORG  CARDINAL  MONEY  PERSON  GPE  DATE  NORP  PERCENT  PRODUCT\n",
              "Frequency     36        31     30      18   17    15     2        2        1"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis with Lexicons"
      ],
      "metadata": {
        "id": "TiIESscnkkA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dAcg1g19kVGa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}